{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = ps.read_csv('/home/k8user/Downloads/9408623-b237fa5848349a14a14e5d4107dc7897c21951f5/wine.csv')\n",
    "data = pd.read_csv(\"/home/k8user/Downloads/UCI_Credit_Card.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=6f1392f2-570a-4eaf-a598-7a9b644a1a38 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands?.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('6f1392f2-570a-4eaf-a598-7a9b644a1a38').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default.payment.next.month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272.0</td>\n",
       "      <td>3455.0</td>\n",
       "      <td>3261.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331.0</td>\n",
       "      <td>14948.0</td>\n",
       "      <td>15549.0</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314.0</td>\n",
       "      <td>28959.0</td>\n",
       "      <td>29547.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940.0</td>\n",
       "      <td>19146.0</td>\n",
       "      <td>19131.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>36681.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0   1    20000.0    2          2         1   24      2      2     -1     -1   \n",
       "1   2   120000.0    2          2         2   26     -1      2      0      0   \n",
       "2   3    90000.0    2          2         2   34      0      0      0      0   \n",
       "3   4    50000.0    2          2         1   37      0      0      0      0   \n",
       "4   5    50000.0    1          2         1   57     -1      0     -1      0   \n",
       "\n",
       "   ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0  ...        0.0        0.0        0.0       0.0     689.0       0.0   \n",
       "1  ...     3272.0     3455.0     3261.0       0.0    1000.0    1000.0   \n",
       "2  ...    14331.0    14948.0    15549.0    1518.0    1500.0    1000.0   \n",
       "3  ...    28314.0    28959.0    29547.0    2000.0    2019.0    1200.0   \n",
       "4  ...    20940.0    19146.0    19131.0    2000.0   36681.0   10000.0   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default.payment.next.month  \n",
       "0       0.0       0.0       0.0                           1  \n",
       "1    1000.0       0.0    2000.0                           1  \n",
       "2    1000.0    1000.0    5000.0                           0  \n",
       "3    1100.0    1069.0    1000.0                           0  \n",
       "4    9000.0     689.0     679.0                           0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                            0\n",
       "LIMIT_BAL                     0\n",
       "SEX                           0\n",
       "EDUCATION                     0\n",
       "MARRIAGE                      0\n",
       "AGE                           0\n",
       "PAY_0                         0\n",
       "PAY_2                         0\n",
       "PAY_3                         0\n",
       "PAY_4                         0\n",
       "PAY_5                         0\n",
       "PAY_6                         0\n",
       "BILL_AMT1                     0\n",
       "BILL_AMT2                     0\n",
       "BILL_AMT3                     0\n",
       "BILL_AMT4                     0\n",
       "BILL_AMT5                     0\n",
       "BILL_AMT6                     0\n",
       "PAY_AMT1                      0\n",
       "PAY_AMT2                      0\n",
       "PAY_AMT3                      0\n",
       "PAY_AMT4                      0\n",
       "PAY_AMT5                      0\n",
       "PAY_AMT6                      0\n",
       "default.payment.next.month    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc =StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sc.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    mean, logsigma = args\n",
    "    batch = tf.shape(mean)[0]\n",
    "    dim = tf.shape(mean)[1]\n",
    "    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "#     epsilon = K.random_normal(shape=(K.shape(mean)[0], 512), mean=0., stddev=1.0)\n",
    "    return mean + K.exp(logsigma / 2) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_shape = x.shape[1]\n",
    "shape = (original_shape,)\n",
    "# inter = 46\n",
    "# inter1 = 32\n",
    "# latent = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss(x):\n",
    "    return K.exp((-K.square(x)))\n",
    "\n",
    "def morlet_wavelet(x):\n",
    "    return (K.cos(1.75 * x)) * K.exp(-x**2/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-26 11:44:45.015387: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K \n",
    "from keras.layers import Layer\n",
    "class WNN_1(Layer):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim \n",
    "        super(WNN_1, self).__init__(**kwargs)\n",
    "    def build(self, input_shape):\n",
    "        # self.input_shape = input_shape[1]\n",
    "        self.kernel = self.add_weight(name = 'kernel',shape = (input_shape[1], self.output_dim),initializer = 'normal', trainable = True)\n",
    "        # self.dilation = self.add_weight(name='dilation', shape = (input_shape[1],),initializer = 'normal', trainable = True)\n",
    "        # self.dilation = self.dilation\n",
    "        # self.translation = self.add_weight(name='translation', shape = (input_shape[1]),initializer = 'normal', trainable = True)\n",
    "        # self.translation = translation\n",
    "        drx = K.random_normal(shape=(1,18))\n",
    "        self.dilation = drx\n",
    "        self.dilation.requires_grad=True\n",
    "        trx = K.random_normal(shape=(1,18))\n",
    "        self.translation = trx\n",
    "        self.translation.requires_grad=True\n",
    "        super(WNN_1, self).build(input_shape)\n",
    "\n",
    "    def call(self, input_data):\n",
    "        v = K.dot(input_data, self.kernel)\n",
    "        # print(v)\n",
    "        v1 = (v  - self.dilation) / self.translation\n",
    "        # v2 = gauss(v1)\n",
    "        v2 = morlet_wavelet(v1)\n",
    "        # print(v1)\n",
    "        return v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K \n",
    "from keras.layers import Layer\n",
    "class WNN_2(Layer):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim \n",
    "        super(WNN_2, self).__init__(**kwargs)\n",
    "    def build(self, input_shape):\n",
    "        # self.input_shape = input_shape[1]\n",
    "        self.kernel = self.add_weight(name = 'kernel',shape = (input_shape[1], self.output_dim),initializer = 'normal', trainable = True)\n",
    "        # self.dilation = self.add_weight(name='dilation', shape = (input_shape[1],),initializer = 'normal', trainable = True)\n",
    "        # self.dilation = self.dilation\n",
    "        # self.translation = self.add_weight(name='translation', shape = (input_shape[1]),initializer = 'normal', trainable = True)\n",
    "        # self.translation = translation\n",
    "        drx = K.random_normal(shape=(1,18))\n",
    "        self.dilation = drx\n",
    "        self.dilation.requires_grad=True\n",
    "        trx = K.random_normal(shape=(1,18))\n",
    "        self.translation = trx\n",
    "        self.translation.requires_grad=True\n",
    "        super(WNN_2, self).build(input_shape)\n",
    "\n",
    "    def call(self, input_data):\n",
    "        v = K.dot(input_data, self.kernel)\n",
    "        # print(v)\n",
    "        v1 = (v  - self.dilation) / self.translation\n",
    "        # v2 = gauss(v1)\n",
    "        v2 = morlet_wavelet(v1)\n",
    "        # print(v1)\n",
    "        return v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "import os\n",
    "from keras import metrics, backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder():\n",
    "    X = Input(shape=shape)\n",
    "    model = WNN_1(18)(X)\n",
    "    # model = Dense(8,activation='relu')(X)\n",
    "\n",
    "    mean = Dense(2)(model)\n",
    "    logsigma = Dense(2)(model)\n",
    "    latent = Lambda(sampling, output_shape=(2,))([mean, logsigma])\n",
    "    meansigma = Model([X], [mean, logsigma, latent])\n",
    "    return meansigma\n",
    "# Lambda(Sampling(), output_shape=(latent,),name='z-samples')([z_mu, z_log_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder():\n",
    "    X = Input(shape=(2,))\n",
    "    model1 = WNN_2(18)(X)\n",
    "    # model1 = Dense(8,activation='relu')(X)\n",
    "   \n",
    "    model = Dense(original_shape,activation='tanh')(model1)\n",
    "    model = Model(X, model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k8user/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "ADAMop = Adam(lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 25)]         0           []                               \n",
      "                                                                                                  \n",
      " wnn_1 (WNN_1)                  (None, 18)           450         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 2)            38          ['wnn_1[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 2)            38          ['wnn_1[0][0]']                  \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 2)            0           ['dense[0][0]',                  \n",
      "                                                                  'dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 526\n",
      "Trainable params: 526\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-26 11:44:52.985040: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-26 11:44:52.986120: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "# encoder\n",
    "E = encoder()\n",
    "# E.compile(optimizer=ADAMop, loss='mse')\n",
    "E.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 2)]               0         \n",
      "                                                                 \n",
      " wnn_2 (WNN_2)               (None, 18)                36        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 25)                475       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 511\n",
      "Trainable params: 511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# generator/decoder\n",
    "G = decoder()\n",
    "# G.compile(optimizer=ADAMop, loss='mse')\n",
    "G.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE\n",
    "X = Input(shape=(shape))\n",
    "# latent_rep = E(X)[0]\n",
    "# output = G(latent_rep)\n",
    "E_mean, E_logsigma, Z = E(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 2) dtype=float32 (created by layer 'model')>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 25), dtype=tf.float32, name=None), name='model_1/dense_2/Tanh:0', description=\"created by layer 'model_1'\")\n"
     ]
    }
   ],
   "source": [
    "output = G(Z)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAE = Model(X, output)\n",
    "# VAE = Model(X, G(E(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 25)]         0           []                               \n",
      "                                                                                                  \n",
      " model (Functional)             [(None, 2),          526         ['input_3[0][0]']                \n",
      "                                 (None, 2),                                                       \n",
      "                                 (None, 2)]                                                       \n",
      "                                                                                                  \n",
      " model_1 (Functional)           (None, 25)           511         ['model[0][2]']                  \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 2)           0           ['model[0][1]']                  \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.square (TFOpLambda)    (None, 2)            0           ['model[0][0]']                  \n",
      "                                                                                                  \n",
      " tf.convert_to_tensor (TFOpLamb  (None, 25)          0           ['model_1[0][0]']                \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.cast (TFOpLambda)           (None, 25)           0           ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " tf.math.subtract (TFOpLambda)  (None, 2)            0           ['tf.__operators__.add[0][0]',   \n",
      "                                                                  'tf.math.square[0][0]']         \n",
      "                                                                                                  \n",
      " tf.math.exp (TFOpLambda)       (None, 2)            0           ['model[0][1]']                  \n",
      "                                                                                                  \n",
      " tf.math.squared_difference (TF  (None, 25)          0           ['tf.convert_to_tensor[0][0]',   \n",
      " OpLambda)                                                        'tf.cast[0][0]']                \n",
      "                                                                                                  \n",
      " tf.math.subtract_1 (TFOpLambda  (None, 2)           0           ['tf.math.subtract[0][0]',       \n",
      " )                                                                'tf.math.exp[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean (TFOpLambd  (None,)             0           ['tf.math.squared_difference[0][0\n",
      " a)                                                              ]']                              \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum (TFOpLambda  (None,)             0           ['tf.math.subtract_1[0][0]']     \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLambda  (None,)             0           ['tf.math.reduce_mean[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None,)              0           ['tf.math.reduce_sum[0][0]']     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None,)             0           ['tf.math.multiply_1[0][0]',     \n",
      " mbda)                                                            'tf.math.multiply[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_1 (TFOpLam  ()                  0           ['tf.__operators__.add_1[0][0]'] \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " add_loss (AddLoss)             ()                   0           ['tf.math.reduce_mean_1[0][0]']  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,037\n",
      "Trainable params: 1,037\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "kl = - 0.5 * K.sum(1 + E_logsigma - K.square(E_mean) - K.exp(E_logsigma), axis=-1)\n",
    "crossent = metrics.mse(X, output)\n",
    "crossent *= original_shape\n",
    "VAEloss = K.mean(crossent + kl)\n",
    "VAE.add_loss(VAEloss)\n",
    "VAE.compile(optimizer=ADAMop)\n",
    "VAE.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pydot\n",
    "import pydot\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(VAE, show_shapes=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 22.5319 - val_loss: 28.5064\n",
      "Epoch 2/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 19.6026 - val_loss: 27.4010\n",
      "Epoch 3/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 19.0220 - val_loss: 27.0063\n",
      "Epoch 4/150\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 18.6354 - val_loss: 26.4321\n",
      "Epoch 5/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 18.4253 - val_loss: 26.4251\n",
      "Epoch 6/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 18.3505 - val_loss: 26.3342\n",
      "Epoch 7/150\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 18.2808 - val_loss: 26.3033\n",
      "Epoch 8/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 18.2293 - val_loss: 26.1245\n",
      "Epoch 9/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 18.1848 - val_loss: 26.1231\n",
      "Epoch 10/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 18.1924 - val_loss: 26.4365\n",
      "Epoch 11/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 18.1540 - val_loss: 26.2261\n",
      "Epoch 12/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 18.1379 - val_loss: 26.2510\n",
      "Epoch 13/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 18.1077 - val_loss: 26.1835\n",
      "Epoch 14/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 18.0902 - val_loss: 26.1614\n",
      "Epoch 15/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 18.0887 - val_loss: 26.1930\n",
      "Epoch 16/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 18.0798 - val_loss: 26.0355\n",
      "Epoch 17/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 18.0876 - val_loss: 26.1997\n",
      "Epoch 18/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 18.0489 - val_loss: 26.2142\n",
      "Epoch 19/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 18.0550 - val_loss: 26.1812\n",
      "Epoch 20/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 18.0466 - val_loss: 26.2786\n",
      "Epoch 21/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 18.0450 - val_loss: 26.1877\n",
      "Epoch 22/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 18.0330 - val_loss: 26.0903\n",
      "Epoch 23/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 18.0410 - val_loss: 26.0294\n",
      "Epoch 24/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 18.0269 - val_loss: 26.0134\n",
      "Epoch 25/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 18.0132 - val_loss: 26.1412\n",
      "Epoch 26/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 18.0003 - val_loss: 26.2440\n",
      "Epoch 27/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 18.0121 - val_loss: 25.9704\n",
      "Epoch 28/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 18.0090 - val_loss: 26.0368\n",
      "Epoch 29/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 18.0226 - val_loss: 26.0442\n",
      "Epoch 30/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 18.0036 - val_loss: 26.1906\n",
      "Epoch 31/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 17.9997 - val_loss: 26.2372\n",
      "Epoch 32/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.9903 - val_loss: 26.1203\n",
      "Epoch 33/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 17.9997 - val_loss: 26.0110\n",
      "Epoch 34/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 17.9933 - val_loss: 26.2012\n",
      "Epoch 35/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 17.9885 - val_loss: 26.0437\n",
      "Epoch 36/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 17.9704 - val_loss: 26.1338\n",
      "Epoch 37/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 17.9828 - val_loss: 25.9555\n",
      "Epoch 38/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 17.9988 - val_loss: 26.0128\n",
      "Epoch 39/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 17.9822 - val_loss: 26.0064\n",
      "Epoch 40/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 17.9633 - val_loss: 25.9248\n",
      "Epoch 41/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 17.9712 - val_loss: 25.8826\n",
      "Epoch 42/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 17.9722 - val_loss: 25.9456\n",
      "Epoch 43/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 17.9538 - val_loss: 25.9316\n",
      "Epoch 44/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 17.9505 - val_loss: 26.1082\n",
      "Epoch 45/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 17.9645 - val_loss: 26.2011\n",
      "Epoch 46/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.9819 - val_loss: 26.0608\n",
      "Epoch 47/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 17.9658 - val_loss: 26.1551\n",
      "Epoch 48/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 17.9358 - val_loss: 26.0117\n",
      "Epoch 49/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 17.9436 - val_loss: 26.0280\n",
      "Epoch 50/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 17.9499 - val_loss: 26.1563\n",
      "Epoch 51/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 17.9244 - val_loss: 25.9686\n",
      "Epoch 52/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 17.9264 - val_loss: 25.7752\n",
      "Epoch 53/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 17.9432 - val_loss: 26.0172\n",
      "Epoch 54/150\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 17.9415 - val_loss: 26.0591\n",
      "Epoch 55/150\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 17.9238 - val_loss: 26.0523\n",
      "Epoch 56/150\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 17.9218 - val_loss: 25.9628\n",
      "Epoch 57/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 17.9213 - val_loss: 25.9942\n",
      "Epoch 58/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.9156 - val_loss: 25.9396\n",
      "Epoch 59/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.9256 - val_loss: 26.0715\n",
      "Epoch 60/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 17.9219 - val_loss: 26.0867\n",
      "Epoch 61/150\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 17.9038 - val_loss: 25.7905\n",
      "Epoch 62/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.9131 - val_loss: 25.9631\n",
      "Epoch 63/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.9244 - val_loss: 25.9281\n",
      "Epoch 64/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.9113 - val_loss: 25.9262\n",
      "Epoch 65/150\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 17.9119 - val_loss: 25.8109\n",
      "Epoch 66/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.8937 - val_loss: 25.8513\n",
      "Epoch 67/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.8881 - val_loss: 26.0205\n",
      "Epoch 68/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.8837 - val_loss: 25.9368\n",
      "Epoch 69/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.8909 - val_loss: 25.9762\n",
      "Epoch 70/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.8857 - val_loss: 25.9492\n",
      "Epoch 71/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.8838 - val_loss: 25.9147\n",
      "Epoch 72/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.9148 - val_loss: 25.8810\n",
      "Epoch 73/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.8948 - val_loss: 25.8670\n",
      "Epoch 74/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.8821 - val_loss: 25.9578\n",
      "Epoch 75/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.8929 - val_loss: 25.7950\n",
      "Epoch 76/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.8982 - val_loss: 25.9732\n",
      "Epoch 77/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.8917 - val_loss: 25.9083\n",
      "Epoch 78/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.8619 - val_loss: 25.7994\n",
      "Epoch 79/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.8662 - val_loss: 25.6853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.8674 - val_loss: 25.9460\n",
      "Epoch 81/150\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 17.8741 - val_loss: 25.7668\n",
      "Epoch 82/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.8621 - val_loss: 25.8366\n",
      "Epoch 83/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.8580 - val_loss: 25.8669\n",
      "Epoch 84/150\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 17.8510 - val_loss: 25.9575\n",
      "Epoch 85/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.8669 - val_loss: 25.9876\n",
      "Epoch 86/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.8626 - val_loss: 25.7368\n",
      "Epoch 87/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.8772 - val_loss: 25.7043\n",
      "Epoch 88/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.8746 - val_loss: 25.9427\n",
      "Epoch 89/150\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 17.8630 - val_loss: 25.9045\n",
      "Epoch 90/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.8470 - val_loss: 25.8211\n",
      "Epoch 91/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.8466 - val_loss: 25.8505\n",
      "Epoch 92/150\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 17.8634 - val_loss: 26.0409\n",
      "Epoch 93/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.8463 - val_loss: 25.8392\n",
      "Epoch 94/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.8362 - val_loss: 25.7750\n",
      "Epoch 95/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.8545 - val_loss: 25.9115\n",
      "Epoch 96/150\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 17.8391 - val_loss: 25.8296\n",
      "Epoch 97/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 17.8462 - val_loss: 25.8689\n",
      "Epoch 98/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.8417 - val_loss: 25.7694\n",
      "Epoch 99/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.8387 - val_loss: 25.8617\n",
      "Epoch 100/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.8224 - val_loss: 25.8176\n",
      "Epoch 101/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.8235 - val_loss: 25.9379\n",
      "Epoch 102/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.8034 - val_loss: 25.8661\n",
      "Epoch 103/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.8354 - val_loss: 25.8206\n",
      "Epoch 104/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.8337 - val_loss: 25.8994\n",
      "Epoch 105/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.8033 - val_loss: 25.7523\n",
      "Epoch 106/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.8274 - val_loss: 25.7863\n",
      "Epoch 107/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.7914 - val_loss: 25.8198\n",
      "Epoch 108/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.7817 - val_loss: 25.7263\n",
      "Epoch 109/150\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 17.8022 - val_loss: 25.8568\n",
      "Epoch 110/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.7666 - val_loss: 25.7708\n",
      "Epoch 111/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.7771 - val_loss: 25.6855\n",
      "Epoch 112/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.7642 - val_loss: 25.7078\n",
      "Epoch 113/150\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 17.7725 - val_loss: 25.8113\n",
      "Epoch 114/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.7516 - val_loss: 25.6708\n",
      "Epoch 115/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.7768 - val_loss: 25.7105\n",
      "Epoch 116/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.7586 - val_loss: 25.5991\n",
      "Epoch 117/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.7414 - val_loss: 25.7351\n",
      "Epoch 118/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.7508 - val_loss: 25.6052\n",
      "Epoch 119/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.7437 - val_loss: 25.6933\n",
      "Epoch 120/150\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 17.7346 - val_loss: 25.5652\n",
      "Epoch 121/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.7240 - val_loss: 25.7334\n",
      "Epoch 122/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.7287 - val_loss: 25.6165\n",
      "Epoch 123/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.7201 - val_loss: 25.5864\n",
      "Epoch 124/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.7366 - val_loss: 25.6032\n",
      "Epoch 125/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.7345 - val_loss: 25.8173\n",
      "Epoch 126/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.7313 - val_loss: 25.7512\n",
      "Epoch 127/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.7273 - val_loss: 25.8680\n",
      "Epoch 128/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 17.7192 - val_loss: 25.6014\n",
      "Epoch 129/150\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 17.7349 - val_loss: 25.5549\n",
      "Epoch 130/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.7478 - val_loss: 25.5860\n",
      "Epoch 131/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.7409 - val_loss: 25.7979\n",
      "Epoch 132/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.7243 - val_loss: 25.6535\n",
      "Epoch 133/150\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 17.6909 - val_loss: 25.5533\n",
      "Epoch 134/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.7214 - val_loss: 25.7177\n",
      "Epoch 135/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.7095 - val_loss: 25.4918\n",
      "Epoch 136/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.7329 - val_loss: 25.6835\n",
      "Epoch 137/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.6946 - val_loss: 25.5032\n",
      "Epoch 138/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.7139 - val_loss: 25.6263\n",
      "Epoch 139/150\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 17.7093 - val_loss: 25.6488\n",
      "Epoch 140/150\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 17.7013 - val_loss: 25.5978\n",
      "Epoch 141/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.7198 - val_loss: 25.6392\n",
      "Epoch 142/150\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 17.7052 - val_loss: 25.7074\n",
      "Epoch 143/150\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 17.6962 - val_loss: 25.7144\n",
      "Epoch 144/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.7071 - val_loss: 25.6375\n",
      "Epoch 145/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.6946 - val_loss: 25.6318\n",
      "Epoch 146/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.7032 - val_loss: 25.5759\n",
      "Epoch 147/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.6963 - val_loss: 25.6558\n",
      "Epoch 148/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.7068 - val_loss: 25.7317\n",
      "Epoch 149/150\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 17.7049 - val_loss: 25.4748\n",
      "Epoch 150/150\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 17.7076 - val_loss: 25.6481\n"
     ]
    }
   ],
   "source": [
    "model1 = VAE.fit(x, x, batch_size=64, validation_split=0.1, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = [5,8,10]\n",
    "lat_dim = [2,5]\n",
    "epoch = [50,100,150]\n",
    "lr = [0.001,0.005,0.009,0.01]\n",
    "moment = [0.001,0.005,0.009,0.008,0.01]\n",
    "batch_size = [32,64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value = None\n",
    "best_mse = None\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "# mses_adam = []\n",
    "# for i in range(len(epoch)):\n",
    "#     for j in range(len(lr)):\n",
    "#         for b in range(len(batch_size)):\n",
    "#             start = time.time()\n",
    "#             # vae.add_loss(vae_loss)\n",
    "#             VAE.compile(optimizer=Adam(learning_rate=lr[j]))\n",
    "#             VAE.fit(x, x, epochs=epoch[i],batch_size=batch_size[b], validation_split=0.1)\n",
    "#             X_predict = VAE.predict(x)\n",
    "#             print(mean_squared_error(x, X_predict))\n",
    "#             mses_adam.append(mean_squared_error(x, X_predict))\n",
    "# #             for error in mses_adam:\n",
    "# #                 if (max_value is None or error > max_value):\n",
    "# #                     max_value = error\n",
    "                    \n",
    "# #                     best_mse = VAE\n",
    "#             elapsed_time_fl = (time.time() - start)\n",
    "#             print(\"elapsed time for each combination: \",elapsed_time_fl)\n",
    "#             print(\"\\n\")\n",
    "#             print(\"==================================================================\")\n",
    "            \n",
    "# print(best_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(epoch)):\n",
    "#     for j in range(len(lr)):\n",
    "#         for b in range(len(batch_size)):\n",
    "#             print(epoch[i],lr[j],batch_size[b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(mses_adam)\n",
    "# mses_adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (pd.DataFrame(mses_adam)).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 2s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "pred=VAE.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(VAE.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9bcaf291-1e5d-401a-b558-976deac06647",
   "metadata": {},
   "source": [
    "## New Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470b1701-0e3b-4a9d-b0cd-7fb08dfdbe3e",
   "metadata": {
    "id": "1Hw1u1V2YlfY"
   },
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder1():\n",
    "    X = Input(shape=shape)\n",
    "    model = WNN_1(18)(X)\n",
    "    # model = Dense(8,activation='relu')(X)\n",
    "\n",
    "    mean = Dense(2)(model)\n",
    "    logsigma = Dense(2)(model)\n",
    "    latent = Lambda(sampling, output_shape=(2,))([mean, logsigma])\n",
    "    meansigma = Model([X], [mean, logsigma, latent])\n",
    "    return meansigma\n",
    "# Lambda(Sampling(), output_shape=(latent,),name='z-samples')([z_mu, z_log_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder1():\n",
    "    X = Input(shape=(2,))\n",
    "    model1 = WNN_2(18)(X)\n",
    "    # model1 = Dense(8,activation='relu')(X)\n",
    "   \n",
    "#     model = Dense(original_shape,activation='tanh')(model1)\n",
    "    model = Model(X, model1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "ADAMop1 = Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 25)]         0           []                               \n",
      "                                                                                                  \n",
      " wnn_1_1 (WNN_1)                (None, 18)           450         ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 2)            38          ['wnn_1_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 2)            38          ['wnn_1_1[0][0]']                \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              (None, 2)            0           ['dense_3[0][0]',                \n",
      "                                                                  'dense_4[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 526\n",
      "Trainable params: 526\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# encoder\n",
    "E1 = encoder1()\n",
    "# E.compile(optimizer=ADAMop, loss='mse')\n",
    "E1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 2)]               0         \n",
      "                                                                 \n",
      " wnn_2_1 (WNN_2)             (None, 18)                36        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36\n",
      "Trainable params: 36\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# generator/decoder\n",
    "G1 = decoder1()\n",
    "# G.compile(optimizer=ADAMop, loss='mse')\n",
    "G1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE\n",
    "X1 = Input(shape=(shape))\n",
    "# latent_rep = E(X)[0]\n",
    "# output = G(latent_rep)\n",
    "E_mean1, E_logsigma1, Z1 = E1(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 2) dtype=float32 (created by layer 'model_3')>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 18), dtype=tf.float32, name=None), name='model_4/wnn_2_1/mul_1:0', description=\"created by layer 'model_4'\")\n"
     ]
    }
   ],
   "source": [
    "output1 = G1(Z1)\n",
    "print(output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAE1 = Model(X1, output1)\n",
    "# VAE = Model(X, G(E(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 25)]              0         \n",
      "                                                                 \n",
      " model_3 (Functional)        [(None, 2),               526       \n",
      "                              (None, 2),                         \n",
      "                              (None, 2)]                         \n",
      "                                                                 \n",
      " model_4 (Functional)        (None, 18)                36        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 562\n",
      "Trainable params: 562\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "VAE1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)           [(None, 25)]         0           []                               \n",
      "                                                                                                  \n",
      " model_3 (Functional)           [(None, 2),          526         ['input_6[0][0]']                \n",
      "                                 (None, 2),                                                       \n",
      "                                 (None, 2)]                                                       \n",
      "                                                                                                  \n",
      " model_4 (Functional)           (None, 18)           36          ['model_3[0][2]']                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 2)           0           ['model_3[0][1]']                \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.math.square_1 (TFOpLambda)  (None, 2)            0           ['model_3[0][0]']                \n",
      "                                                                                                  \n",
      " tf.math.subtract_2 (TFOpLambda  (None, 2)           0           ['tf.__operators__.add_2[0][0]', \n",
      " )                                                                'tf.math.square_1[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.exp_1 (TFOpLambda)     (None, 2)            0           ['model_3[0][1]']                \n",
      "                                                                                                  \n",
      " tf.math.subtract_3 (TFOpLambda  (None, 2)           0           ['tf.math.subtract_2[0][0]',     \n",
      " )                                                                'tf.math.exp_1[0][0]']          \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_1 (TFOpLamb  (None,)             0           ['tf.math.subtract_3[0][0]']     \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.multiply_2 (TFOpLambda  (None,)             0           ['tf.math.reduce_sum_1[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_2 (TFOpLam  ()                  0           ['tf.math.multiply_2[0][0]']     \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " add_loss_1 (AddLoss)           ()                   0           ['tf.math.reduce_mean_2[0][0]']  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 562\n",
      "Trainable params: 562\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "kl1 = - 0.5 * K.sum(1 + E_logsigma1 - K.square(E_mean1) - K.exp(E_logsigma1), axis=-1)\n",
    "# crossent1 = metrics.mse(X1, output1)\n",
    "# crossent1 *= original_shape\n",
    "VAEloss1 = K.mean(kl1)\n",
    "VAE1.add_loss(VAEloss1)\n",
    "VAE1.compile(optimizer=ADAMop1)\n",
    "VAE1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0a84dc41-3271-40fb-9804-08001032549f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_weights=VAE.get_weights()[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f356b5dd-4f25-4a89-bc13-2fd2306cb74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAE1.set_weights(new_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0db37268-d476-4808-a01d-9e0f130dc886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 1s 722us/step\n"
     ]
    }
   ],
   "source": [
    "X_pred_new = VAE1.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fb4958f1-8679-4483-bc91-fb998d44b5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.43394221e-02,  5.89395642e-01,  9.77791011e-01, ...,\n",
       "        -2.25243509e-01, -2.74178058e-01,  7.91481853e-01],\n",
       "       [ 7.71471648e-04,  1.08353049e-01,  9.35326278e-01, ...,\n",
       "        -1.03530459e-01,  4.37290192e-01, -2.67468393e-01],\n",
       "       [ 1.19629945e-03,  2.42874905e-01, -2.62411267e-01, ...,\n",
       "        -8.05193931e-02, -1.45253921e-07,  1.08798206e-01],\n",
       "       ...,\n",
       "       [ 8.38897191e-04,  1.11798622e-01,  9.02621686e-01, ...,\n",
       "        -7.84328058e-02,  5.97393155e-01, -2.67480999e-01],\n",
       "       [ 4.68489202e-03,  3.21614325e-01,  7.78891206e-01, ...,\n",
       "        -2.88285792e-01, -3.77301089e-02, -1.43041380e-03],\n",
       "       [ 1.66077586e-03,  2.08558455e-01,  5.09103000e-01, ...,\n",
       "        -2.85572797e-01, -2.19608191e-04, -2.16228947e-01]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pred_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_squared_error(x,X_pred_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predd=sc.inverse_transform(X_pred_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.DataFrame(predd)\n",
    "train = pd.DataFrame(X_pred_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.columns = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=cabf0b2c-8c2c-433b-a437-749a0e3de3e2 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands?.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('cabf0b2c-8c2c-433b-a437-749a0e3de3e2').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.044339</td>\n",
       "      <td>0.589396</td>\n",
       "      <td>0.977791</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.901029</td>\n",
       "      <td>-0.287190</td>\n",
       "      <td>-9.079326e-03</td>\n",
       "      <td>0.118525</td>\n",
       "      <td>-0.285503</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>0.363807</td>\n",
       "      <td>0.608941</td>\n",
       "      <td>3.623079e-23</td>\n",
       "      <td>0.575587</td>\n",
       "      <td>0.053035</td>\n",
       "      <td>-0.225244</td>\n",
       "      <td>-2.741781e-01</td>\n",
       "      <td>0.791482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000771</td>\n",
       "      <td>0.108353</td>\n",
       "      <td>0.935326</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.427541</td>\n",
       "      <td>0.005658</td>\n",
       "      <td>8.742820e-01</td>\n",
       "      <td>-0.277853</td>\n",
       "      <td>-0.000876</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>-0.123530</td>\n",
       "      <td>0.538897</td>\n",
       "      <td>-1.840970e-34</td>\n",
       "      <td>-0.206772</td>\n",
       "      <td>-0.084612</td>\n",
       "      <td>-0.103530</td>\n",
       "      <td>4.372902e-01</td>\n",
       "      <td>-0.267468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.242875</td>\n",
       "      <td>-0.262411</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.782564</td>\n",
       "      <td>-0.226756</td>\n",
       "      <td>2.083051e-09</td>\n",
       "      <td>-0.106709</td>\n",
       "      <td>-0.072151</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.178200</td>\n",
       "      <td>0.408511</td>\n",
       "      <td>-1.222701e-31</td>\n",
       "      <td>-0.038074</td>\n",
       "      <td>-0.142738</td>\n",
       "      <td>-0.080519</td>\n",
       "      <td>-1.452539e-07</td>\n",
       "      <td>0.108798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.207099</td>\n",
       "      <td>-0.257808</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.751018</td>\n",
       "      <td>-0.190451</td>\n",
       "      <td>-3.090129e-07</td>\n",
       "      <td>-0.138388</td>\n",
       "      <td>-0.048976</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.176311</td>\n",
       "      <td>0.401005</td>\n",
       "      <td>-2.951516e-32</td>\n",
       "      <td>-0.087771</td>\n",
       "      <td>-0.208492</td>\n",
       "      <td>-0.079882</td>\n",
       "      <td>-1.546261e-07</td>\n",
       "      <td>-0.002364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.206428</td>\n",
       "      <td>0.716767</td>\n",
       "      <td>0.252460</td>\n",
       "      <td>1.316270e-25</td>\n",
       "      <td>0.940584</td>\n",
       "      <td>-0.281774</td>\n",
       "      <td>7.692809e-01</td>\n",
       "      <td>0.236169</td>\n",
       "      <td>-0.116122</td>\n",
       "      <td>0.002947</td>\n",
       "      <td>-0.259476</td>\n",
       "      <td>0.677881</td>\n",
       "      <td>-8.698037e-20</td>\n",
       "      <td>0.806137</td>\n",
       "      <td>0.491578</td>\n",
       "      <td>0.109946</td>\n",
       "      <td>9.643487e-01</td>\n",
       "      <td>0.968635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "         0         1         2             3         4         5   \\\n",
       "0 -0.044339  0.589396  0.977791 -0.000000e+00  0.901029 -0.287190   \n",
       "1  0.000771  0.108353  0.935326  0.000000e+00  0.427541  0.005658   \n",
       "2  0.001196  0.242875 -0.262411  0.000000e+00  0.782564 -0.226756   \n",
       "3  0.000743  0.207099 -0.257808 -0.000000e+00  0.751018 -0.190451   \n",
       "4 -0.206428  0.716767  0.252460  1.316270e-25  0.940584 -0.281774   \n",
       "\n",
       "             6         7         8         9         10        11  \\\n",
       "0 -9.079326e-03  0.118525 -0.285503  0.000986  0.363807  0.608941   \n",
       "1  8.742820e-01 -0.277853 -0.000876  0.002000 -0.123530  0.538897   \n",
       "2  2.083051e-09 -0.106709 -0.072151 -0.000005 -0.178200  0.408511   \n",
       "3 -3.090129e-07 -0.138388 -0.048976 -0.000005 -0.176311  0.401005   \n",
       "4  7.692809e-01  0.236169 -0.116122  0.002947 -0.259476  0.677881   \n",
       "\n",
       "             12        13        14        15            16        17  \n",
       "0  3.623079e-23  0.575587  0.053035 -0.225244 -2.741781e-01  0.791482  \n",
       "1 -1.840970e-34 -0.206772 -0.084612 -0.103530  4.372902e-01 -0.267468  \n",
       "2 -1.222701e-31 -0.038074 -0.142738 -0.080519 -1.452539e-07  0.108798  \n",
       "3 -2.951516e-32 -0.087771 -0.208492 -0.079882 -1.546261e-07 -0.002364  \n",
       "4 -8.698037e-20  0.806137  0.491578  0.109946  9.643487e-01  0.968635  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['default.payment.next.month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(train,data['default.payment.next.month'],test_size=0.2,stratify=data['default.payment.next.month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    18691\n",
       "1     5309\n",
       "Name: default.payment.next.month, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_model = dt.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_pred = dc_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4673\n",
       "1    1327\n",
       "Name: default.payment.next.month, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4648\n",
       "1    1352\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pd.DataFrame(dc_pred)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_pred.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, classification_report, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7511666666666666"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, dc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.642225109178721"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, dc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3914,  759],\n",
       "       [ 734,  593]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, dc_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay(confusion_matrix=cm,display_labels = dc_model.classes_).plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                              8660.398374\n",
       "LIMIT_BAL                     129747.661567\n",
       "SEX                                0.489129\n",
       "EDUCATION                          0.790349\n",
       "MARRIAGE                           0.521970\n",
       "AGE                                9.217904\n",
       "PAY_0                              1.123802\n",
       "PAY_2                              1.197186\n",
       "PAY_3                              1.196868\n",
       "PAY_4                              1.169139\n",
       "PAY_5                              1.133187\n",
       "PAY_6                              1.149988\n",
       "BILL_AMT1                      73635.860576\n",
       "BILL_AMT2                      71173.768783\n",
       "BILL_AMT3                      69349.387427\n",
       "BILL_AMT4                      64332.856134\n",
       "BILL_AMT5                      60797.155770\n",
       "BILL_AMT6                      59554.107537\n",
       "PAY_AMT1                       16563.280354\n",
       "PAY_AMT2                       23040.870402\n",
       "PAY_AMT3                       17606.961470\n",
       "PAY_AMT4                       15666.159744\n",
       "PAY_AMT5                       15278.305679\n",
       "PAY_AMT6                       17777.465775\n",
       "default.payment.next.month         0.415062\n",
       "dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                              451.232178\n",
       "LIMIT_BAL                     76717.921875\n",
       "SEX                               0.049176\n",
       "EDUCATION                         0.257587\n",
       "MARRIAGE                          0.324539\n",
       "AGE                               4.706163\n",
       "PAY_0                             0.640044\n",
       "PAY_2                             0.749088\n",
       "PAY_3                             0.756167\n",
       "PAY_4                             0.743174\n",
       "PAY_5                             0.714878\n",
       "PAY_6                             0.718945\n",
       "BILL_AMT1                     40494.667969\n",
       "BILL_AMT2                     39839.898438\n",
       "BILL_AMT3                     38826.324219\n",
       "BILL_AMT4                     35787.011719\n",
       "BILL_AMT5                     33543.425781\n",
       "BILL_AMT6                     32739.103516\n",
       "PAY_AMT1                       4595.492676\n",
       "PAY_AMT2                       5558.967285\n",
       "PAY_AMT3                       4527.684570\n",
       "PAY_AMT4                       4288.078613\n",
       "PAY_AMT5                       4194.367676\n",
       "PAY_AMT6                       4875.344238\n",
       "default.payment.next.month        0.216308\n",
       "dtype: float32"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a2a25786-07cb-4756-977e-a0acf30e18bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1323f2c8-8dd5-4e2c-8c8c-792a03d7bb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "af925d77-93b0-4faf-ba22-4565d3bc2422",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# from sklearn.naive_bayes import BernoulliNB\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0202ce85-819c-41a2-8bc7-7393b83a1627",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    models = list()\n",
    "    models.append(LogisticRegression(max_iter=100000))\n",
    "    models.append(KNeighborsClassifier())\n",
    "    models.append(DecisionTreeClassifier())\n",
    "    models.append(RandomForestClassifier())\n",
    "    models.append(AdaBoostClassifier())\n",
    "    models.append(MLPClassifier())\n",
    "#     models.append(BernoulliNB())\n",
    "#     models.append(SVC())\n",
    "    models.append(LGBMClassifier())\n",
    "    models.append(CatBoostClassifier())\n",
    "    models.append(XGBClassifier())\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "66a59ed8-6bd3-408e-a512-9302aaf02721",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_param_grid = [    \n",
    "                {'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "                'C' : np.logspace(-4, 4, 20),\n",
    "                'solver' : ['lbfgs','newton-cg','liblinear','sag','saga'],\n",
    "                'max_iter' : [100, 1000,2500, 5000]\n",
    "                }\n",
    "             ]\n",
    "svc_parameters = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['poly','rbf', 'sigmoid','linear']}\n",
    "\n",
    "\n",
    "knn_parameters = { 'n_neighbors' : [5,7,9,11,13,15], 'weights' : ['uniform','distance'],'metric' : ['minkowski','euclidean','manhattan']}\n",
    "\n",
    "Decis_parameters = {'max_depth': [2, 3, 5, 10, 20], 'min_samples_leaf': [5, 10, 20, 50, 100], 'criterion': [\"gini\", \"entropy\"]}\n",
    "\n",
    "\n",
    "n_estimators = [5,20,50,100] # number of trees in the random forest\n",
    "max_features = ['auto', 'sqrt'] # number of features in consideration at every split\n",
    "max_depth = [int(x) for x in np.linspace(10, 120, num = 12)] # maximum number of levels allowed in each decision tree\n",
    "min_samples_split = [2, 6, 10] # minimum sample number to split a node\n",
    "min_samples_leaf = [1, 3, 4] # minimum sample number that can be stored in a leaf node\n",
    "bootstrap = [True, False] # method used to sample data points\n",
    "\n",
    "rand_parameters = {'n_estimators': n_estimators,'max_features': max_features,'max_depth': max_depth,'min_samples_split': min_samples_split,'min_samples_leaf': min_samples_leaf,'bootstrap': bootstrap}\n",
    "\n",
    "\n",
    "\n",
    "# ada_parameters = dict()\n",
    "# grid['n_estimators'] = [10, 50, 100, 500]\n",
    "# grid['learning_rate'] = [0.0001, 0.001, 0.01, 0.1, 1.0]\n",
    "\n",
    "ada_parameters = {\n",
    "                    'n_estimators': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 20],\n",
    "                    'learning_rate': [(0.97 + x / 100) for x in range(0, 8)],\n",
    "                    'algorithm': ['SAMME', 'SAMME.R']\n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "mlp_parameters = {'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],'activation': ['tanh', 'relu'],'solver': ['sgd', 'adam'],'alpha': [0.0001, 0.05],'learning_rate': ['constant','adaptive']}\n",
    "\n",
    "\n",
    "xgb_parameters ={\n",
    "                'n_estimators': [100, 200, 500],\n",
    "                'learning_rate': [0.01,0.05,0.1],\n",
    "                'booster': ['gbtree', 'gblinear'],\n",
    "                'gamma': [0, 0.5, 1],\n",
    "                'reg_alpha': [0, 0.5, 1],\n",
    "                'reg_lambda': [0.5, 1, 5],\n",
    "                'base_score': [0.2, 0.5, 1]\n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "cat_parameters = {'max_depth': [3,4,5],'n_estimators':[100, 200, 300]}\n",
    "\n",
    "\n",
    "\n",
    "# fit_params={\"early_stopping_rounds\":30, \n",
    "#             \"eval_metric\" : 'auc', \n",
    "#             \"eval_set\" : [(X_test,y_test)],\n",
    "#             'eval_names': ['valid'],\n",
    "#             #'callbacks': [lgb.reset_parameter(learning_rate=learning_rate_010_decay_power_099)],\n",
    "#             'verbose': 100,\n",
    "#             'categorical_feature': 'auto'}\n",
    "\n",
    "\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "lgb_parameters = {'num_leaves': sp_randint(6, 50), \n",
    "                 'min_child_samples': sp_randint(100, 500), \n",
    "                 'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n",
    "                 'subsample': sp_uniform(loc=0.2, scale=0.8), \n",
    "                 'colsample_bytree': sp_uniform(loc=0.4, scale=0.6),\n",
    "                 'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n",
    "                 'reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "05a6700a-3086-48dc-92b5-1ae3fb0e0952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = get_models()\n",
    "len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3a9894f0-fcf9-4621-978a-247e237ad495",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import *\n",
    "from timeit import default_timer as timer\n",
    "from sklearn import metrics\n",
    "import statistics\n",
    "skf = StratifiedKFold(n_splits=10,random_state=42,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d144c566-1cfe-461e-a323-b9a487548e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay, plot_roc_curve, confusion_matrix, accuracy_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "FOLD:  1\n",
      "ROC-SCORE-LogisticRegression:  0.6719291549760688\n",
      "LogisticRegression\n",
      "FOLD:  2\n",
      "ROC-SCORE-LogisticRegression:  0.6824713236507676\n",
      "LogisticRegression\n",
      "FOLD:  3\n",
      "ROC-SCORE-LogisticRegression:  0.6528666033999009\n",
      "LogisticRegression\n",
      "FOLD:  4\n",
      "ROC-SCORE-LogisticRegression:  0.6849289280409308\n",
      "LogisticRegression\n",
      "FOLD:  5\n",
      "ROC-SCORE-LogisticRegression:  0.668481288166364\n",
      "LogisticRegression\n",
      "FOLD:  6\n",
      "ROC-SCORE-LogisticRegression:  0.6796733165538867\n",
      "LogisticRegression\n",
      "FOLD:  7\n",
      "ROC-SCORE-LogisticRegression:  0.6725652836428341\n",
      "LogisticRegression\n",
      "FOLD:  8\n",
      "ROC-SCORE-LogisticRegression:  0.673950630909024\n",
      "LogisticRegression\n",
      "FOLD:  9\n",
      "ROC-SCORE-LogisticRegression:  0.6794542641782693\n",
      "LogisticRegression\n",
      "FOLD:  10\n",
      "ROC-SCORE-LogisticRegression:  0.6461168648361882\n",
      "================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for model in models:\n",
    "count = 0\n",
    "AUC_logistic = []\n",
    "for train_index, test_index in skf.split(train, y):\n",
    "    print(\"LogisticRegression\")\n",
    "    count+=1\n",
    "    print(\"FOLD: \",count)\n",
    "    # print(\"Model : \", model)\n",
    "    # specific \".loc\" syntax for working with dataframes\n",
    "    x_train, x_test = train.loc[train_index], train.loc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    x_train = sc.fit_transform(x_train)\n",
    "    x_test = sc.transform(x_test)\n",
    "    package = LogisticRegression()\n",
    "    clf = GridSearchCV(package,param_grid=lr_param_grid)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_predict = clf.predict(x_test)\n",
    "    cm = confusion_matrix(y_test, y_predict)\n",
    "    roc_score=roc_auc_score(y_test,y_predict)\n",
    "    AUC_logistic.append(roc_score)\n",
    "    print(\"ROC-SCORE-LogisticRegression: \", roc_score)\n",
    "    # print('\\n')\n",
    "print(\"================================================================\")\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier\n",
      "FOLD:  1\n",
      "<========================AUC====================================>\n",
      "ROC-SCORE-KNeighborsClassifier:  0.6701214102987292\n",
      "KNeighborsClassifier\n",
      "FOLD:  2\n",
      "<========================AUC====================================>\n",
      "ROC-SCORE-KNeighborsClassifier:  0.680116871595973\n",
      "KNeighborsClassifier\n",
      "FOLD:  3\n",
      "<========================AUC====================================>\n",
      "ROC-SCORE-KNeighborsClassifier:  0.6473015349067502\n",
      "KNeighborsClassifier\n",
      "FOLD:  4\n",
      "<========================AUC====================================>\n",
      "ROC-SCORE-KNeighborsClassifier:  0.6873220622214887\n",
      "KNeighborsClassifier\n",
      "FOLD:  5\n",
      "<========================AUC====================================>\n",
      "ROC-SCORE-KNeighborsClassifier:  0.6558064449579137\n",
      "KNeighborsClassifier\n",
      "FOLD:  6\n",
      "<========================AUC====================================>\n",
      "ROC-SCORE-KNeighborsClassifier:  0.6712070886284865\n",
      "KNeighborsClassifier\n",
      "FOLD:  7\n",
      "<========================AUC====================================>\n",
      "ROC-SCORE-KNeighborsClassifier:  0.6688158427190368\n",
      "KNeighborsClassifier\n",
      "FOLD:  8\n",
      "<========================AUC====================================>\n",
      "ROC-SCORE-KNeighborsClassifier:  0.6736669783940039\n",
      "KNeighborsClassifier\n",
      "FOLD:  9\n",
      "<========================AUC====================================>\n",
      "ROC-SCORE-KNeighborsClassifier:  0.6695912886730677\n",
      "KNeighborsClassifier\n",
      "FOLD:  10\n",
      "<========================AUC====================================>\n",
      "ROC-SCORE-KNeighborsClassifier:  0.6649434534354869\n",
      "<================================================================>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for model in models:\n",
    "count = 0\n",
    "AUC_KNN = []\n",
    "for train_index, test_index in skf.split(train, y):\n",
    "    print(\"KNeighborsClassifier\")\n",
    "    count+=1\n",
    "    print(\"FOLD: \",count)\n",
    "    # print(\"Model : \", model)\n",
    "    # specific \".loc\" syntax for working with dataframes\n",
    "    x_train, x_test = train.loc[train_index], train.loc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    x_train = sc.fit_transform(x_train)\n",
    "    x_test = sc.transform(x_test)\n",
    "    package = KNeighborsClassifier()\n",
    "    clf = GridSearchCV(package,param_grid=knn_parameters)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_predict = clf.predict(x_test)\n",
    "    cm = confusion_matrix(y_test, y_predict)\n",
    "    roc_score=roc_auc_score(y_test,y_predict)\n",
    "    AUC_KNN.append(roc_score)\n",
    "    print(\"<========================AUC====================================>\")\n",
    "    print(\"ROC-SCORE-KNeighborsClassifier: \", roc_score)\n",
    "    # print('\\n')\n",
    "print(\"<================================================================>\")\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier\n",
      "FOLD:  1\n",
      "<========================AUC====================================>\n",
      "ROC-SCORE-DecisionTreeClassifier:  0.6660881539858062\n",
      "DecisionTreeClassifier\n",
      "FOLD:  2\n",
      "<========================AUC====================================>\n",
      "ROC-SCORE-DecisionTreeClassifier:  0.6726589577488035\n",
      "DecisionTreeClassifier\n",
      "FOLD:  3\n",
      "<========================AUC====================================>\n",
      "ROC-SCORE-DecisionTreeClassifier:  0.6372364457831325\n",
      "DecisionTreeClassifier\n",
      "FOLD:  4\n",
      "<========================AUC====================================>\n",
      "ROC-SCORE-DecisionTreeClassifier:  0.6756555330912691\n",
      "DecisionTreeClassifier\n",
      "FOLD:  5\n",
      "<========================AUC====================================>\n",
      "ROC-SCORE-DecisionTreeClassifier:  0.6577096055454695\n",
      "DecisionTreeClassifier\n",
      "FOLD:  6\n",
      "<========================AUC====================================>\n",
      "ROC-SCORE-DecisionTreeClassifier:  0.665446030698135\n",
      "DecisionTreeClassifier\n",
      "FOLD:  7\n",
      "<========================AUC====================================>\n",
      "ROC-SCORE-DecisionTreeClassifier:  0.6675805505375844\n",
      "DecisionTreeClassifier\n",
      "FOLD:  8\n",
      "<========================AUC====================================>\n",
      "ROC-SCORE-DecisionTreeClassifier:  0.6557978380450631\n",
      "DecisionTreeClassifier\n",
      "FOLD:  9\n",
      "<========================AUC====================================>\n",
      "ROC-SCORE-DecisionTreeClassifier:  0.6697306946872755\n",
      "DecisionTreeClassifier\n",
      "FOLD:  10\n",
      "<========================AUC====================================>\n",
      "ROC-SCORE-DecisionTreeClassifier:  0.6465660619930801\n",
      "<================================================================>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for model in models:\n",
    "count = 0\n",
    "AUC_Decision = []\n",
    "for train_index, test_index in skf.split(train, y):\n",
    "    print(\"DecisionTreeClassifier\")\n",
    "    count+=1\n",
    "    print(\"FOLD: \",count)\n",
    "    # print(\"Model : \", model)\n",
    "    # specific \".loc\" syntax for working with dataframes\n",
    "    x_train, x_test = train.loc[train_index], train.loc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    x_train = sc.fit_transform(x_train)\n",
    "    x_test = sc.transform(x_test)\n",
    "    package = DecisionTreeClassifier()\n",
    "    clf = GridSearchCV(package,param_grid=Decis_parameters)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_predict = clf.predict(x_test)\n",
    "    cm = confusion_matrix(y_test, y_predict)\n",
    "    roc_score=roc_auc_score(y_test,y_predict)\n",
    "    AUC_Decision.append(roc_score)\n",
    "    print(\"<========================AUC====================================>\")\n",
    "    print(\"ROC-SCORE-DecisionTreeClassifier: \", roc_score)\n",
    "    # print('\\n')\n",
    "print(\"<================================================================>\")\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n",
      "FOLD:  1\n",
      "<========================AUC====================================>\n",
      "ROC-SCORE-RandomForestClassifier:  0.6725558054134345\n",
      "RandomForestClassifier\n",
      "FOLD:  2\n",
      "<========================AUC====================================>\n",
      "ROC-SCORE-RandomForestClassifier:  0.6752506601749464\n",
      "RandomForestClassifier\n",
      "FOLD:  3\n"
     ]
    }
   ],
   "source": [
    "# for model in models:\n",
    "count = 0\n",
    "AUC_RF = []\n",
    "for train_index, test_index in skf.split(train, y):\n",
    "    print(\"RandomForestClassifier\")\n",
    "    count+=1\n",
    "    print(\"FOLD: \",count)\n",
    "    # print(\"Model : \", model)\n",
    "    # specific \".loc\" syntax for working with dataframes\n",
    "    x_train, x_test = train.loc[train_index], train.loc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    x_train = sc.fit_transform(x_train)\n",
    "    x_test = sc.transform(x_test)\n",
    "    package = RandomForestClassifier()\n",
    "    clf = GridSearchCV(package,param_grid=rand_parameters)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_predict = clf.predict(x_test)\n",
    "    cm = confusion_matrix(y_test, y_predict)\n",
    "    roc_score=roc_auc_score(y_test,y_predict)\n",
    "    AUC_RF.append(roc_score)\n",
    "    print(\"<========================AUC====================================>\")\n",
    "    print(\"ROC-SCORE-RandomForestClassifier: \", roc_score)\n",
    "    # print('\\n')\n",
    "print(\"<================================================================>\")\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model in models:\n",
    "count = 0\n",
    "AUC_ABC = []\n",
    "for train_index, test_index in skf.split(train, y):\n",
    "    print(\"AdaBoostClassifier\")\n",
    "    count+=1\n",
    "    print(\"FOLD: \",count)\n",
    "    # print(\"Model : \", model)\n",
    "    # specific \".loc\" syntax for working with dataframes\n",
    "    x_train, x_test = train.loc[train_index], train.loc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    x_train = sc.fit_transform(x_train)\n",
    "    x_test = sc.transform(x_test)\n",
    "    package = AdaBoostClassifier()\n",
    "    clf = GridSearchCV(package,param_grid=ada_parameters)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_predict = clf.predict(x_test)\n",
    "    cm = confusion_matrix(y_test, y_predict)\n",
    "    roc_score=roc_auc_score(y_test,y_predict)\n",
    "    AUC_ABC.append(roc_score)\n",
    "    print(\"<========================AUC====================================>\")\n",
    "    print(\"ROC-SCORE-AdaBoostClassifier: \", roc_score)\n",
    "    # print('\\n')\n",
    "print(\"<================================================================>\")\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model in models:\n",
    "count = 0\n",
    "AUC_MLP = []\n",
    "for train_index, test_index in skf.split(train, y):\n",
    "    print(\"MLPClassifier\")\n",
    "    count+=1\n",
    "    print(\"FOLD: \",count)\n",
    "    # print(\"Model : \", model)\n",
    "    # specific \".loc\" syntax for working with dataframes\n",
    "    x_train, x_test = train.loc[train_index], train.loc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    x_train = sc.fit_transform(x_train)\n",
    "    x_test = sc.transform(x_test)\n",
    "    package = MLPClassifier()\n",
    "    clf = GridSearchCV(package,param_grid=mlp_parameters)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_predict = clf.predict(x_test)\n",
    "    cm = confusion_matrix(y_test, y_predict)\n",
    "    roc_score=roc_auc_score(y_test,y_predict)\n",
    "    AUC_MLP.append(roc_score)\n",
    "    print(\"<========================AUC====================================>\")\n",
    "    print(\"ROC-SCORE-MLPClassifier: \", roc_score)\n",
    "    # print('\\n')\n",
    "print(\"<================================================================>\")\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model in models:\n",
    "count = 0\n",
    "AUC_LGB = []\n",
    "for train_index, test_index in skf.split(train, y):\n",
    "    print(\"LGBMClassifier\")\n",
    "    count+=1\n",
    "    print(\"FOLD: \",count)\n",
    "    # print(\"Model : \", model)\n",
    "    # specific \".loc\" syntax for working with dataframes\n",
    "    x_train, x_test = train.loc[train_index], train.loc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    x_train = sc.fit_transform(x_train)\n",
    "    x_test = sc.transform(x_test)\n",
    "    package = LGBMClassifier()\n",
    "    clf = GridSearchCV(package,param_grid=lgb_parameters)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_predict = clf.predict(x_test)\n",
    "    cm = confusion_matrix(y_test, y_predict)\n",
    "    roc_score=roc_auc_score(y_test,y_predict)\n",
    "    AUC_LGB.append(roc_score)\n",
    "    print(\"<========================AUC====================================>\")\n",
    "    print(\"ROC-SCORE-LGBMClassifier: \", roc_score)\n",
    "    # print('\\n')\n",
    "print(\"<================================================================>\")\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model in models:\n",
    "count = 0\n",
    "AUC_CAT = []\n",
    "for train_index, test_index in skf.split(train, y):\n",
    "    print(\"CatBoostClassifier\")\n",
    "    count+=1\n",
    "    print(\"FOLD: \",count)\n",
    "    # print(\"Model : \", model)\n",
    "    # specific \".loc\" syntax for working with dataframes\n",
    "    x_train, x_test = train.loc[train_index], train.loc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    x_train = sc.fit_transform(x_train)\n",
    "    x_test = sc.transform(x_test)\n",
    "    package = CatBoostClassifier()\n",
    "    clf = GridSearchCV(package,param_grid=cat_parameters)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_predict = clf.predict(x_test)\n",
    "    cm = confusion_matrix(y_test, y_predict)\n",
    "    roc_score=roc_auc_score(y_test,y_predict)\n",
    "    AUC_CAT.append(roc_score)\n",
    "    print(\"<========================AUC====================================>\")\n",
    "    print(\"ROC-SCORE-CatBoostClassifier: \", roc_score)\n",
    "    # print('\\n')\n",
    "print(\"<================================================================>\")\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model in models:\n",
    "count = 0\n",
    "AUC_XGB = []\n",
    "for train_index, test_index in skf.split(train, y):\n",
    "    print(\"XGBClassifier\")\n",
    "    count+=1\n",
    "    print(\"FOLD: \",count)\n",
    "    # print(\"Model : \", model)\n",
    "    # specific \".loc\" syntax for working with dataframes\n",
    "    x_train, x_test = train.loc[train_index], train.loc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    x_train = sc.fit_transform(x_train)\n",
    "    x_test = sc.transform(x_test)\n",
    "    package = XGBClassifier()\n",
    "    clf = GridSearchCV(package,param_grid=xgb_parameters)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_predict = clf.predict(x_test)\n",
    "    cm = confusion_matrix(y_test, y_predict)\n",
    "    roc_score=roc_auc_score(y_test,y_predict)\n",
    "    AUC_XGB.append(roc_score)\n",
    "    print(\"<========================AUC====================================>\")\n",
    "    print(\"ROC-SCORE-XGBClassifier: \", roc_score)\n",
    "    # print('\\n')\n",
    "print(\"<================================================================>\")\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product is : 6\n"
     ]
    }
   ],
   "source": [
    "a,b= [int(x) for x in input(\"Enter 2 numbers :\").split(',')]\n",
    "print(\"Product is :\", a*b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer is : 16.72\n"
     ]
    }
   ],
   "source": [
    "a,b,c = [float(x) for x in input(\"Enter 3 numbers :\").split(',')]\n",
    "print(\"Answer is :\", a+b*c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Durga Soft\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello\",end=' ')\n",
    "print(\"Durga\",end=' ')\n",
    "print(\"Soft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Durga Your Age is 48\n",
      "You are teaching java and Python\n"
     ]
    }
   ],
   "source": [
    "s=\"Durga\"\n",
    "a=48\n",
    "s1=\"java\"\n",
    "s2=\"Python\"\n",
    "print(\"Hello\",s,\"Your Age is\",a)\n",
    "print(\"You are teaching\",s1,\"and\",s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a value is 10\n",
      "b value is 20 and c value is 30\n"
     ]
    }
   ],
   "source": [
    "a = 10\n",
    "b = 20\n",
    "c = 30\n",
    "\n",
    "print(\"a value is %i\"%a)\n",
    "print(\"b value is %d and c value is %d\"%(b,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n"
     ]
    }
   ],
   "source": [
    "for x in range(10) :\n",
    "    print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for x in range(11) :\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n",
      "5\n",
      "7\n",
      "9\n",
      "11\n",
      "13\n",
      "15\n",
      "17\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "for x in range(21) :\n",
    "    if (x%2!=0):\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for x in range(10,0,-1) :\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n",
      "6\n",
      "10\n",
      "The Sum= 10\n"
     ]
    }
   ],
   "source": [
    "list=eval(input(\"Enter List:\"))\n",
    "sum=0;\n",
    "for x in list:\n",
    "    sum=sum+x;\n",
    "    print(sum)\n",
    "print(\"The Sum=\",sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "x = 1\n",
    "\n",
    "while x<=10:\n",
    "    print(x)\n",
    "    x = x + 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sum of first 10 number is: 55\n"
     ]
    }
   ],
   "source": [
    "n = int(input(\"Enter number:\"))\n",
    "sum= 0\n",
    "i = 1\n",
    "\n",
    "while i <=n:\n",
    "    sum = sum+i\n",
    "    i = i+1\n",
    "print(\"The sum of first\",n,\"number is:\",sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thanks for confirmation\n"
     ]
    }
   ],
   "source": [
    "name=\"\"\n",
    "while name!=\"durga\":\n",
    "    name=input(\"Enter Name:\")\n",
    "print(\"Thanks for confirmation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* \n",
      "* * \n",
      "* * * \n",
      "* * * * \n"
     ]
    }
   ],
   "source": [
    "n = int(input(\"Enter number of rows:\"))\n",
    "for i in range(1,n+1):\n",
    "    # print(i)\n",
    "    for j in range(1,i+1):\n",
    "        # print(j)\n",
    "        print(\"*\",end=\" \")\n",
    "    print()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*\n",
      "**\n",
      "***\n",
      "****\n"
     ]
    }
   ],
   "source": [
    "n = int(input(\"Enter number of rows:\"))\n",
    "for i in range(1, n+1):\n",
    "    print(\"*\" * i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        * \n",
      "       * * \n",
      "      * * * \n",
      "     * * * * \n",
      "    * * * * * \n",
      "   * * * * * * \n",
      "  * * * * * * * \n",
      " * * * * * * * * \n"
     ]
    }
   ],
   "source": [
    "n = int(input(\"Enter number of rows:\"))\n",
    "for i in range(1, n+1):\n",
    "    print(\" \" * (n-i),end=\" \")\n",
    "    print(\"* \"*i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       * \n",
      "      * * \n",
      "     * * * \n",
      "    * * * * \n",
      "   * * * * * \n",
      "  * * * * * * \n",
      " * * * * * * * \n",
      "* * * * * * * * \n"
     ]
    }
   ],
   "source": [
    "n = int(input(\"Enter number of rows:\"))\n",
    "for i in range(1,n+1):\n",
    " print(\" \" * (n-i),end=\"\")\n",
    " print(\"* \"*i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The character present at positive index 0 and at negative index -6 is p\n",
      "The character present at positive index 1 and at negative index -5 is r\n",
      "The character present at positive index 2 and at negative index -4 is a\n",
      "The character present at positive index 3 and at negative index -3 is n\n",
      "The character present at positive index 4 and at negative index -2 is a\n",
      "The character present at positive index 5 and at negative index -1 is y\n"
     ]
    }
   ],
   "source": [
    "s = input(\"Enter some string:\")\n",
    "i = 0\n",
    "for x in s:\n",
    "    print(\"The character present at positive index {} and at negative index {} is {}\".format(i, i-len(s), x))\n",
    "    i = i+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f54efdc28531de1995e52c0eecdf52900ad9e9477f9701aef19b980541d74d14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
